# Handcrafted

## Efficient

- [1608.08021] [PVANET: Deep but Lightweight Neural Networks for Real-time Object Detection](https://arxiv.org/abs/1608.08021)

- [1610.02357] [Xception: Deep Learning with Depthwise Separable Convolutions](https://arxiv.org/abs/1610.02357)

- [1612.08242] [YOLO9000: Better, Faster, Stronger](https://arxiv.org/abs/1612.08242)

- [1704.04861] [MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications](https://arxiv.org/abs/1704.04861)

- [1707.01083] [ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices](https://arxiv.org/abs/1707.01083)

- [1708.05234] [FaceBoxes: A CPU Real-time Face Detector with High Accuracy](https://arxiv.org/abs/1708.05234)

- [1711.07264] [Light-Head R-CNN: In Defense of Two-Stage Object Detector](https://arxiv.org/abs/1711.07264)

- [1801.04381] [MobileNetV2: Inverted Residuals and Linear Bottlenecks](https://arxiv.org/abs/1801.04381)

- [1803.10615] [SqueezeNext: Hardware-Aware Neural Network Design](https://arxiv.org/abs/1803.10615)

- [1807.11164] [ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design](https://arxiv.org/abs/1807.11164)

## High accuracy

- [2012] [ImageNet Classification with Deep Convolutional Neural Networks](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks)

- [1409.1556] [Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556)

- [1409.4842] [Going Deeper with Convolutions](https://arxiv.org/abs/1409.4842)

- [1512.00567] [Rethinking the Inception Architecture for Computer Vision](https://arxiv.org/abs/1512.00567)

- [1512.03385] [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)

- [1602.07261] [Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning](https://arxiv.org/abs/1602.07261)

- [1603.05027] [Identity Mappings in Deep Residual Networks](https://arxiv.org/abs/1603.05027)

- [1608.06993] [Densely Connected Convolutional Networks](https://arxiv.org/abs/1608.06993)

- [1804.02767] [YOLOv3: An Incremental Improvement](https://arxiv.org/abs/1804.02767)

# Automated

- [1707.07012] [Learning Transferable Architectures for Scalable Image Recognition](https://arxiv.org/abs/1707.07012)

- [1807.11626] [MnasNet: Platform-Aware Neural Architecture Search for Mobile](https://arxiv.org/abs/1807.11626)

- [1812.00332] [ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware](https://arxiv.org/abs/1812.00332)

- [1812.03443] [FBNet: Hardware-Aware Efficient ConvNet Design via Differentiable Neural Architecture Search](https://arxiv.org/abs/1812.03443)

- [1812.08934] [ChamNet: Towards Efficient Network Design through Platform-Aware Model
Adaptation](https://arxiv.org/abs/1812.08934)

- [1901.02985] [Auto-DeepLab: Hierarchical Neural Architecture Search for Semantic Image Segmentation](https://arxiv.org/abs/1901.02985)

- [1905.11946] [EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks](https://arxiv.org/abs/1905.11946)

# Useful component

- [1904.05049] [Drop an octave: Reducing spatial redundancy in convolutional neural networks with octave convolution](https://arxiv.org/pdf/1904.05049) # Octave conv 

- [1502.03167] [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/abs/1502.03167)

- [1603.05201] [Understanding and Improving Convolutional Neural Networks via Concatenated Rectified Linear Units](https://arxiv.org/abs/1603.05201) # CReLU

- [1702.03275] [Batch Renormalization: Towards Reducing Minibatch Dependence in Batch-Normalized Models](https://arxiv.org/abs/1702.03275)

- [1709.01507] [Squeeze-and-Excitation Networks](https://arxiv.org/abs/1709.01507) # SE

- [1708.02002] [Focal Loss for Dense Object Detection](https://arxiv.org/abs/1708.02002)

# Activation function

- [1502.01852] [Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification](https://arxiv.org/abs/1502.01852) # PReLU

# Weight initialization

- [2018] [Residual Learning Without Normalization via Better Initialization](https://openreview.net/forum?id=H1gsz30cKX) # ZeroInit

# Feature fusion

- [CVPR2019] [Nas-fpn: Learning scalable feature pyramid architecture for object detection](http://openaccess.thecvf.com/content_CVPR_2019/papers/Ghiasi_NAS-FPN_Learning_Scalable_Feature_Pyramid_Architecture_for_Object_Detection_CVPR_2019_paper.pdf)

- [CVPR2018] [Path aggregation network for instance segmentation](http://openaccess.thecvf.com/content_cvpr_2018/papers/Liu_Path_Aggregation_Network_CVPR_2018_paper.pdf)

- [CVPR2017] [Feature pyramid networks for object detection](http://openaccess.thecvf.com/content_cvpr_2017/html/Lin_Feature_Pyramid_Networks_CVPR_2017_paper.html)

- [1804.02767] [Yolov3: An incremental improvement](https://arxiv.org/abs/1804.02767)

- [1706.05587] [Rethinking atrous convolution for semantic image segmentation](https://arxiv.org/pdf/1706.05587) # ASPP

- [CVPR2017] [Pyramid scene parsing network](http://openaccess.thecvf.com/content_cvpr_2017/papers/Zhao_Pyramid_Scene_Parsing_CVPR_2017_paper.pdf) # PSP

- [CVPR2016] [Hypernet: Towards accurate region proposal generation and joint object detection](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Kong_HyperNet_Towards_Accurate_CVPR_2016_paper.pdf)

- [1612.06851] [Beyond skip connections: Top-down modulation for object detection](https://arxiv.org/pdf/1612.06851) #TDM
